{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9361088,"sourceType":"datasetVersion","datasetId":5675842}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Conv3D, MaxPooling3D, LSTM, Dense, Dropout, BatchNormalization, TimeDistributed, Flatten, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score, roc_auc_score\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport glob\nimport cv2\nimport os\nimport matplotlib.pyplot as plt\n\n# Check for GPU availability and set memory growth before any other TensorFlow operations\nphysical_devices = tf.config.list_physical_devices('GPU')\nif len(physical_devices) > 0:\n    print(f\"Using GPU: {physical_devices}\")\n\n# Constants\nIMG_SIZE = (128, 128)\nMAX_FRAMES = 30\nBATCH_SIZE = 16\nEPOCHS = 30\nLEARNING_RATE = 0.0005\nWEIGHT_DECAY = 0.0001\n\n# Data Augmentation\ntrain_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1.0/255.0,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.2\n)\n\ntest_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255.0)\n\n# Paths\nreal_videos = '/kaggle/input/dataset/data/real'\nfake_videos = '/kaggle/input/dataset/data/fake'\n\n# Function to extract frames from videos\ndef extract_frames(video_path, img_size=IMG_SIZE, max_frames=MAX_FRAMES):\n    cap = cv2.VideoCapture(video_path)\n    frames = []\n    frame_count = 0\n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            break\n        if frame_count >= max_frames:\n            break\n        frame = cv2.resize(frame, img_size)\n        frames.append(frame)\n        frame_count += 1\n    cap.release()\n    # Padding with zeros if there are fewer frames than MAX_FRAMES\n    if len(frames) < max_frames:\n        frames.extend([np.zeros_like(frames[0])] * (max_frames - len(frames)))\n    return np.array(frames)\n\n# Load and preprocess dataset\ndef load_dataset(real_videos, fake_videos, img_size=IMG_SIZE, max_frames=MAX_FRAMES):\n    real_paths = glob.glob(os.path.join(real_videos, '*.mp4'))\n    fake_paths = glob.glob(os.path.join(fake_videos, '*.mp4'))\n\n    data, labels = [], []\n    \n    for video_path in real_paths:\n        frames = extract_frames(video_path, img_size, max_frames)\n        data.append(frames)\n        labels.append(0)  # Real video is labeled as 0\n\n    for video_path in fake_paths:\n        frames = extract_frames(video_path, img_size, max_frames)\n        data.append(frames)\n        labels.append(1)  # Fake video is labeled as 1\n    \n    return np.array(data), np.array(labels)\n\n# Load dataset\ndata, labels = load_dataset(real_videos, fake_videos)\n\n# Split into train, test, validation\ntrain_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=42)\ntrain_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)\n\n# Model Building: CNN + LSTM\ninput_shape = (MAX_FRAMES, IMG_SIZE[0], IMG_SIZE[1], 3)\n\ninput_flow = Input(shape=input_shape)\nx = Conv3D(32, (3, 3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(WEIGHT_DECAY))(input_flow)\nx = MaxPooling3D((2, 2, 2))(x)\nx = BatchNormalization()(x)\n\nx = Conv3D(64, (3, 3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(WEIGHT_DECAY))(x)\nx = MaxPooling3D((2, 2, 2))(x)\nx = BatchNormalization()(x)\n\nx = Conv3D(128, (3, 3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(WEIGHT_DECAY))(x)\nx = MaxPooling3D((2, 2, 2))(x)\nx = BatchNormalization()(x)\n\nx = Conv3D(256, (3, 3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(WEIGHT_DECAY))(x)\nx = MaxPooling3D((2, 2, 2))(x)\nx = BatchNormalization()(x)\n\nx = TimeDistributed(Flatten())(x)\nx = LSTM(128, return_sequences=True)(x)\nx = LSTM(64)(x)\n\nx = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(WEIGHT_DECAY))(x)\nx = Dropout(0.5)(x)\noutput = Dense(1, activation='sigmoid')(x)\n\nmodel = Model(inputs=input_flow, outputs=output)\nmodel.compile(optimizer=Adam(learning_rate=LEARNING_RATE), loss='binary_crossentropy', metrics=['accuracy'])\n\n# Callbacks\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\nlr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n\n# Clear memory before training\ntf.keras.backend.clear_session()\n\n# Training the Model\nhistory = model.fit(\n    train_data, train_labels, \n    validation_data=(val_data, val_labels), \n    epochs=EPOCHS, \n    batch_size=BATCH_SIZE,\n    callbacks=[early_stopping, lr_scheduler],\n    verbose=1\n)\n\n# Save the Model\nmodel.save('video_classification_model.h5')\n\n# Plot training and validation graphs\ndef plot_training_history(history, save_path_loss='plot_loss.png', save_path_accuracy='plot_accuracy.png'):\n    plt.figure(figsize=(12, 4))\n\n    # Plot Accuracy\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('Model Accuracy')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='upper left')\n\n    # Save Accuracy Plot\n    plt.savefig(save_path_accuracy)  # Save the accuracy plot\n    plt.clf()  # Clear the figure\n\n    # Plot Loss\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model Loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='upper left')\n\n    # Save Loss Plot\n    plt.savefig(save_path_loss)  # Save the loss plot\n    plt.show()\n\n# Save the training and validation graphs\nplot_training_history(history, 'training_accuracy_plot.png', 'training_loss_plot.png')\n\n# Evaluation\ntest_loss, test_accuracy = model.evaluate(test_data, test_labels)\nprint(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n\n# Predictions and metrics\npreds_proba = model.predict(test_data)\npreds = (preds_proba > 0.5).astype(\"int32\")\n\n# Classification Report\nreport = classification_report(test_labels, preds, target_names=['Real', 'Fake'], output_dict=True)\n\n# Extract metrics for Fake\nprecision_fake = report['Fake']['precision']\nrecall_fake = report['Fake']['recall']\nf1_score_fake = report['Fake']['f1-score']\n\n# Extract metrics for Real\nprecision_real = report['Real']['precision']\nrecall_real = report['Real']['recall']\nf1_score_real = report['Real']['f1-score']\n\n# Overall Accuracy\noverall_accuracy = report['accuracy']\n\n# Print Metrics\nprint(f\"Precision for Fake: {precision_fake:.2f}\")\nprint(f\"Recall for Fake: {recall_fake:.2f}\")\nprint(f\"F1-Score for Fake: {f1_score_fake:.2f}\")\nprint(f\"Precision for Real: {precision_real:.2f}\")\nprint(f\"Recall for Real: {recall_real:.2f}\")\nprint(f\"F1-Score for Real: {f1_score_real:.2f}\")\nprint(f\"Overall Accuracy: {overall_accuracy:.2f}\")\n\n# Display full classification report\nprint(\"\\nFull Classification Report:\")\nprint(classification_report(test_labels, preds, target_names=['Real', 'Fake']))\n\n# Confusion Matrix\ncm = confusion_matrix(test_labels, preds)\nprint('Confusion Matrix:')\nprint(cm)\n\n# Model Summary\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T12:10:09.091888Z","iopub.execute_input":"2024-09-14T12:10:09.092256Z","iopub.status.idle":"2024-09-14T12:34:49.938084Z","shell.execute_reply.started":"2024-09-14T12:10:09.092218Z","shell.execute_reply":"2024-09-14T12:34:49.937215Z"},"trusted":true},"execution_count":null,"outputs":[]}]}